{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tutorial here](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/model-tuning/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a single hyperparameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning is implemented as a model wrapper. We wrap a model in a tuning strategy 9e.g. cross-validation) and bind the wrapped model to data in a machine. Fitting the machine searches for optimal model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Repos/mike_scratch/mlj_tutorial/A-model-tuning`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/mph/.julia/packages/MLJModels/tMgLW/src/loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJDecisionTreeInterface.DecisionTreeClassifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MLJ\n",
    "using PrettyPrinting\n",
    "X, y = @load_iris\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify a range of values using the `range` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericRange(1 ≤ max_depth ≤ 5; origin=3.0, unit=2.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "r = range(dtc, :max_depth, lower=1, upper=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hyperparameters of other types (e.g. `Symbol`), you use values=... keyword."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the model in a `TunedModel` specifying the tuning strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = DecisionTreeClassifier(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 1,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = false,\n",
       "            merge_purity_threshold = 1.0,\n",
       "            pdf_smoothing = 0.0,\n",
       "            display_depth = 5,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    tuning = Grid(\n",
       "            goal = nothing,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = Holdout(\n",
       "            fraction_train = 0.7,\n",
       "            shuffle = false,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = LogLoss(tol = 2.220446049250313e-16),\n",
       "    weights = nothing,\n",
       "    operation = nothing,\n",
       "    range = MLJBase.NumericRange{Int64, MLJBase.Bounded, Symbol}[NumericRange(1 ≤ max_depth ≤ 5; origin=3.0, unit=2.0)],\n",
       "    selection_heuristic = MLJTuning.NaiveSelection(nothing),\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPU1{Nothing}(nothing),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true,\n",
       "    cache = true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tm = TunedModel(model=dtc, ranges=[r, ], measure=cross_entropy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping this in a tuning strategy above creates a \"self-tuning\" version of the model, `tuned_model = TunedModel(model=...)`. Some further key-word arguments include:\n",
    "1. the algorithm (i.e. tuning strategy) for searching the hyper-parameter space of the model. E.g. `tuning = Random(rng=123)` or `tuning = Grid(goal=100)`.\n",
    "2. the resampling strategy, used to evaluate performance for each value of the hyper-parameters (e.g. `resampling=CV(nfolds=9, rng=123)` or `resampling=Holdout(fraction_train=0.7)`).\n",
    "3. the measure (or measures) on which to base performance evaluations (and for reporting purposes) (e.g. `measure = rms` or `measures = [rms, mae]`).\n",
    "4. the range, usually describing the \"space\" of hyperparameters to be searched (but more generallly whatever extra information is required to complete the search specification, e.g. initial values in gradient-decent)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and inpsecting a tuned model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a tuned model like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{ProbabilisticTunedModel{Grid,…},…}.\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/MuLnJ/src/machines.jl:464\n",
      "┌ Info: Attempting to evaluate 5 models.\n",
      "└ @ MLJTuning /Users/mph/.julia/packages/MLJTuning/Al9yX/src/tuned_models.jl:680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 5 metamodels:   0%[>                        ]  ETA: N/A\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 5 metamodels:  20%[=====>                   ]  ETA: 0:00:18\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 5 metamodels:  40%[==========>              ]  ETA: 0:00:07\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 5 metamodels:  80%[====================>    ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 5 metamodels: 100%[=========================] Time: 0:00:04\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{ProbabilisticTunedModel{Grid,…},…} trained 1 time; caches data\n",
       "  model: MLJTuning.ProbabilisticTunedModel{Grid, MLJDecisionTreeInterface.DecisionTreeClassifier}\n",
       "  args: \n",
       "    1:\tSource @450 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @906 ⏎ `AbstractVector{Multiclass{3}}`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = machine(tm, X, y)\n",
    "fit!(m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the misclassification rate for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3978952727983693"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = report(m)\n",
    "r.best_history_entry.measurement[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the plotting vectors you need are in r.plotting. I can't get Plots to compile right now though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning nested hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with dummy regression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (x1=rand(100), x2=rand(100), x3=rand(100))\n",
    "y = 2X.x1 - X.x2 + 0.05 * randn(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple model with decision tree regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/mph/.julia/packages/MLJModels/tMgLW/src/loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeterministicEnsembleModel(\n",
       "    model = DecisionTreeRegressor(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 5,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = false,\n",
       "            merge_purity_threshold = 1.0,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    atomic_weights = Float64[],\n",
       "    bagging_fraction = 0.8,\n",
       "    rng = Random._GLOBAL_RNG(),\n",
       "    n = 100,\n",
       "    acceleration = CPU1{Nothing}(nothing),\n",
       "    out_of_bag_measure = Any[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\n",
    "forest = EnsembleModel(model=DecisionTreeRegressor())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the ensemble (bagging function) has a set of hyperparameters (`atomic_weights`, `bagging_fraction`, `n`). But so does the atomic decision tree model (`max_depth`, `min_sample_leaf`, etc.)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, we need to specify the range to tune the hyperparameters. To do this with nested hyperparameters, we can use the dot syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{DeterministicTunedModel{Grid,…},…}.\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/MuLnJ/src/machines.jl:464\n",
      "┌ Info: Attempting to evaluate 36 models.\n",
      "└ @ MLJTuning /Users/mph/.julia/packages/MLJTuning/Al9yX/src/tuned_models.jl:680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:   0%[>                        ]  ETA: N/A\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:   3%[>                        ]  ETA: 0:01:08\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:   6%[=>                       ]  ETA: 0:00:37\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:   8%[==>                      ]  ETA: 0:00:24\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  11%[==>                      ]  ETA: 0:00:18\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  14%[===>                     ]  ETA: 0:00:14\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  17%[====>                    ]  ETA: 0:00:11\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  19%[====>                    ]  ETA: 0:00:09\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  22%[=====>                   ]  ETA: 0:00:08\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  25%[======>                  ]  ETA: 0:00:07\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  28%[======>                  ]  ETA: 0:00:06\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  31%[=======>                 ]  ETA: 0:00:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  33%[========>                ]  ETA: 0:00:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  36%[=========>               ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  39%[=========>               ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  42%[==========>              ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  44%[===========>             ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  47%[===========>             ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  50%[============>            ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  53%[=============>           ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  56%[=============>           ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  58%[==============>          ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  61%[===============>         ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  64%[===============>         ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  67%[================>        ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  69%[=================>       ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  72%[==================>      ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  75%[==================>      ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  78%[===================>     ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  81%[====================>    ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  83%[====================>    ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  86%[=====================>   ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  89%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  92%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  94%[=======================> ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels:  97%[========================>]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 36 metamodels: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "r1 = range(forest, :(model.n_subfeatures), lower=1, upper=3)\n",
    "r2 = range(forest, :bagging_fraction, lower=0.4, upper=1.0)\n",
    "tm = TunedModel(model=forest, tuning=Grid(resolution=12),\n",
    "                resampling=CV(nfolds=6), ranges=[r1, r2],\n",
    "                measures=rms)\n",
    "m = machine(tm, X, y)\n",
    "fit!(m);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now inspect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17825570569802807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = report(m)\n",
    "r.best_history_entry.measurement[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36×2 Matrix{Any}:\n",
       " 2  1.0\n",
       " 3  0.945455\n",
       " 1  0.836364\n",
       " 3  1.0\n",
       " 1  0.781818\n",
       " 2  0.563636\n",
       " 2  0.672727\n",
       " 1  0.890909\n",
       " 3  0.781818\n",
       " 3  0.836364\n",
       " ⋮  \n",
       " 1  0.672727\n",
       " 2  0.836364\n",
       " 1  0.618182\n",
       " 1  0.4\n",
       " 3  0.454545\n",
       " 1  0.454545\n",
       " 3  0.509091\n",
       " 3  0.890909\n",
       " 1  0.727273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.plotting.parameter_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column corresponds with the sub-features parameter. The second corresponds wit the bagging fraction. If I could plot this, we'd use color to denote `r.plotting.measurements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36-element Vector{Float64}:\n",
       " 0.18452788340498058\n",
       " 0.19088183453012386\n",
       " 0.2858790075691232\n",
       " 0.21781686623825347\n",
       " 0.2896629044540661\n",
       " 0.20952788650417342\n",
       " 0.1951252257374061\n",
       " 0.2845816168040688\n",
       " 0.18157145313270476\n",
       " 0.18020907715082793\n",
       " ⋮\n",
       " 0.2949112622907113\n",
       " 0.17979269055524033\n",
       " 0.30936970156981486\n",
       " 0.3274552339296205\n",
       " 0.20787884281047223\n",
       " 0.32213146199045795\n",
       " 0.19784923395691326\n",
       " 0.18239215809509213\n",
       " 0.29653275879300794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.plotting.measurements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
