{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to tutorial page](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/ensembles/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/Personal Stuff/Repos/mike_scratch/mlj_tutorial/A-ensembles`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The active manifest file has dependencies that were resolved with a different julia version (1.7.1). Unexpected behavior may occur.\n",
      "└ @ nothing /Users/michaelherman/Documents/Personal Stuff/Repos/mike_scratch/mlj_tutorial/A-ensembles/Manifest.toml:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ColorTypes ─────────────── v0.11.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Crayons ────────────────── v4.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJTuning ──────────────── v0.6.16\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StableRNGs ─────────────── v1.0.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJEnsembles ───────────── v0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JSON ───────────────────── v0.21.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Conda ──────────────────── v1.6.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ScientificTypesBase ────── v3.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJModelInterface ──────── v1.3.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CategoricalDistributions ─ v0.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsFuns ──────────────── v0.9.14\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Preferences ────────────── v1.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatisticalTraits ──────── v3.0.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJSerialization ───────── v1.1.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SpecialFunctions ───────── v2.0.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PyCall ─────────────────── v1.93.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CategoricalArrays ──────── v0.10.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJIteration ───────────── v0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PrettyTables ───────────── v1.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PooledArrays ───────────── v1.4.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataAPI ────────────────── v1.9.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PDMats ─────────────────── v0.11.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Tables ─────────────────── v1.6.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StaticArrays ───────────── v1.3.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JLSO ───────────────────── v2.6.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJBase ────────────────── v0.19.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IniFile ────────────────── v0.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ARFFFiles ──────────────── v1.4.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ProgressMeter ──────────── v1.7.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RecipesBase ────────────── v1.2.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NearestNeighbors ───────── v0.4.9\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ScientificTypes ────────── v3.0.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JLLWrappers ────────────── v1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m VersionParsing ─────────── v1.2.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OpenML ─────────────────── v0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PyPlot ─────────────────── v2.10.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m EarlyStopping ──────────── v0.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NearestNeighborModels ──── v0.1.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m URIs ───────────────────── v1.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TranscodingStreams ─────── v0.9.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parsers ────────────────── v2.1.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ─────────── v1.11.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJ ────────────────────── v0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InvertedIndices ────────── v1.1.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FillArrays ─────────────── v0.12.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m QuadGK ─────────────────── v2.4.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FilePathsBase ──────────── v0.9.17\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IterationControl ───────── v0.5.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HTTP ───────────────────── v0.9.17\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Memento ────────────────── v1.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataFrames ─────────────── v1.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LearnBase ──────────────── v0.4.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BSON ───────────────────── v0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MbedTLS ────────────────── v1.0.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LogExpFunctions ────────── v0.3.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataStructures ─────────── v0.18.11\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJModels ──────────────── v0.15.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Colors ─────────────────── v0.12.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnicodePlots ───────────── v2.5.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ComputationalResources ─── v0.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PrettyPrinting ─────────── v0.3.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MacroTools ─────────────── v0.5.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Compat ─────────────────── v3.41.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsAPI ───────────────── v1.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnPack ─────────────────── v1.0.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parameters ─────────────── v0.12.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Distributions ──────────── v0.25.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Missings ───────────────── v1.0.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SortingAlgorithms ──────── v1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InverseFunctions ───────── v0.1.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChangesOfVariables ─────── v0.1.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DocStringExtensions ────── v0.8.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsBase ──────────────── v0.33.14\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LossFunctions ──────────── v0.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LatinHypercubeSampling ─── v1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/6cdc8832ba11c7695f494c9d9a1c31e90959ce0f/build.log`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/71fd4022ecd0c6d20180e23ff1b3e05a143959c2/build.log`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mUnPack\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInvertedIndices\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInverseFunctions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCompat\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBSON\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLearnBase\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mStableRNGs\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mScientificTypesBase\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIniFile\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPDMats\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mEarlyStopping\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFillArrays\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDocStringExtensions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mPrettyPrinting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRecipesBase\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mURIs\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDataAPI\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsAPI\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mComputationalResources\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPreferences\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDensityInterface\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mParameters\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mProgressMeter\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTranscodingStreams\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMemento\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCrayons\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMbedTLS\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatisticalTraits\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFilePathsBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPooledArrays\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIterationControl\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMissings\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMacroTools\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTables\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJLLWrappers\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistances\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDataStructures\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCodecZlib\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJModelInterface\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSpecFun_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRmath_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalArrays\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSortingAlgorithms\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChangesOfVariables\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mQuadGK\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHTTP\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRmath\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJLSO\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mARFFFiles\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPrettyTables\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenML\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPyCall\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorTypes\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLatinHypercubeSampling\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLossFunctions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mUnicodePlots\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColors\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mNearestNeighborModels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsFuns\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mPyPlot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistributions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalDistributions\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mScientificTypes\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mDataFrames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJModels\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJBase\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJEnsembles\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJTuning\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJIteration\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJSerialization\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mMLJ\n",
      "  77 dependencies successfully precompiled in 64 seconds. 21 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "import DataFrames: DataFrame\n",
    "using PrettyPrinting\n",
    "using StableRNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  201, 202, 203, 204, 205, 206, 207, 208, 209, 210], [211, 212, 213, 214, 215, 216, 217, 218, 219, 220  …  291, 292, 293, 294, 295, 296, 297, 298, 299, 300])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = StableRNG(512)\n",
    "Xraw = rand(rng, 300, 3)\n",
    "y = exp.(Xraw[:,1] - Xraw[:,2] - 2Xraw[:,3] + 0.1*rand(rng,300))\n",
    "X = DataFrame(Xraw, :auto)\n",
    "\n",
    "train, test = partition(eachindex(y), 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/michaelherman/.julia/packages/MLJModels/tMgLW/src/loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import NearestNeighborModels ✔"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNNRegressor(\n",
       "    K = 10,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = NearestNeighborModels.Uniform())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load a simple model\n",
    "KNNRegressor = @load KNNRegressor\n",
    "knn_model = KNNRegressor(K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{KNNRegressor,…} trained 0 times; caches data\n",
       "  model: NearestNeighborModels.KNNRegressor\n",
       "  args: \n",
       "    1:\tSource @415 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @368 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = machine(knn_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{KNNRegressor,…}.\n",
      "└ @ MLJBase /Users/michaelherman/.julia/packages/MLJBase/MuLnJ/src/machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06389980172436367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit!(knn, rows=train)\n",
    "ŷ = predict(knn, rows=test)\n",
    "rms(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  measure, measurement, operation, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_pairs\n",
       "Extract:\n",
       "┌────────────────────────┬─────────────┬───────────┬──────────┐\n",
       "│\u001b[22m measure                \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m operation \u001b[0m│\u001b[22m per_fold \u001b[0m│\n",
       "├────────────────────────┼─────────────┼───────────┼──────────┤\n",
       "│ RootMeanSquaredError() │ 0.124       │ predict   │ [0.124]  │\n",
       "└────────────────────────┴─────────────┴───────────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We could have done the following instead.\n",
    "evaluate!(knn, resampling=Holdout(fraction_train=0.7, rng=StableRNG(666)), measure=rms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogenous ensebles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic support for ensembles like bagging -- ensembles of simple atomic models. This is done using the `EnsembleModel` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeterministicEnsembleModel(\n",
       "    model = KNNRegressor(\n",
       "            K = 10,\n",
       "            algorithm = :kdtree,\n",
       "            metric = Distances.Euclidean(0.0),\n",
       "            leafsize = 10,\n",
       "            reorder = true,\n",
       "            weights = NearestNeighborModels.Uniform()),\n",
       "    atomic_weights = Float64[],\n",
       "    bagging_fraction = 0.8,\n",
       "    rng = Random._GLOBAL_RNG(),\n",
       "    n = 20,\n",
       "    acceleration = CPU1{Nothing}(nothing),\n",
       "    out_of_bag_measure = Any[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_model = EnsembleModel(model=knn_model, n=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `n=20` indicates how many models are present in the ensemble."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing an ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test it like any other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  measure, measurement, operation, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_pairs\n",
       "Extract:\n",
       "┌────────────────────────┬─────────────┬───────────┬────────────────────────────\n",
       "│\u001b[22m measure                \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m operation \u001b[0m│\u001b[22m per_fold                 \u001b[0m ⋯\n",
       "├────────────────────────┼─────────────┼───────────┼────────────────────────────\n",
       "│ RootMeanSquaredError() │ 0.0854      │ predict   │ [0.09, 0.114, 0.0778, 0.0 ⋯\n",
       "└────────────────────────┴─────────────┴───────────┴────────────────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble = machine(ensemble_model, X, y)\n",
    "estimates = evaluate!(ensemble, resampling=CV())\n",
    "estimates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses `rms`, the default measure for regressions. We can take the mean measurement over the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimates.measurement[1] = 0.08539224487561968\n",
      "mean(estimates.per_fold[1]) = 0.08375076479161388\n"
     ]
    }
   ],
   "source": [
    "@show estimates.measurement[1];\n",
    "@show mean(estimates.per_fold[1]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify multiple measurements as well. Here we're only showing one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simultaneously tune the ensemble's `bagging_fraction` and the k-nearest neighbor hyperparameter K. The KNN model is a field of the ensemble, so we need to use nested hyperparameters. The `params` function will show the nested parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(model = (K = 10,\n",
      "          algorithm = :kdtree,\n",
      "          metric = Distances.Euclidean(0.0),\n",
      "          leafsize = 10,\n",
      "          reorder = true,\n",
      "          weights = NearestNeighborModels.Uniform()),\n",
      " atomic_weights = [],\n",
      " bagging_fraction = 0.8,\n",
      " rng = Random._GLOBAL_RNG(),\n",
      " n = 20,\n",
      " acceleration = CPU1{Nothing}(nothing),\n",
      " out_of_bag_measure = [])"
     ]
    }
   ],
   "source": [
    "params(ensemble_model) |> pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to define the tuning grid. Construct ranges for the two parameters and collate the ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_range = range(ensemble_model, :bagging_fraction, lower=0.5, upper=1.0)\n",
    "K_range = range(ensemble_model, :(model.K), lower=1, upper=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a linear scale by default. But we can use `:log10` for logarithmic ranges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note\n",
    "The `:(model.K)` above looks weird. From what I can deduce, using `:model.k` syntactically parses to something like `(:model).K` -- the `K` object of the `model` symbol. That's not what we want. We want the `model.K` symbol. So the paretheses help that. We can use `dump(Meta.parse(\"...\"))` to better understand what's happening syntactically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any}((5,))\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Symbol range\n",
      "    2: Symbol ensemble_model\n",
      "    3: Expr\n",
      "      head: Symbol quote\n",
      "      args: Array{Any}((1,))\n",
      "        1: Expr\n",
      "          head: Symbol .\n",
      "          args: Array{Any}((2,))\n",
      "            1: Symbol model\n",
      "            2: QuoteNode\n",
      "              value: Symbol K\n",
      "    4: Expr\n",
      "      head: Symbol kw\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol lower\n",
      "        2: Int64 1\n",
      "    5: Expr\n",
      "      head: Symbol kw\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol upper\n",
      "        2: Int64 20\n"
     ]
    }
   ],
   "source": [
    "dump(Meta.parse(\"range(ensemble_model, :(model.K), lower=1, upper=20)\"))L"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to just using `:model.K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{Any}((5,))\n",
      "    1: Symbol range\n",
      "    2: Symbol ensemble_model\n",
      "    3: Expr\n",
      "      head: Symbol .\n",
      "      args: Array{Any}((2,))\n",
      "        1: QuoteNode\n",
      "          value: Symbol model\n",
      "        2: QuoteNode\n",
      "          value: Symbol K\n",
      "    4: Expr\n",
      "      head: Symbol kw\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol lower\n",
      "        2: Int64 1\n",
      "    5: Expr\n",
      "      head: Symbol kw\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol upper\n",
      "        2: Int64 20\n"
     ]
    }
   ],
   "source": [
    "dump(Meta.parse(\"range(ensemble_model, :model.K, lower=1, upper=20)\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the first version we see `head: Symbol quote` in the Symbol ensemble_model section. In the second version, this is `head: Symbol`. So the intuition above is correct. The `:(model.K)` quotes the symbol appropriately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anyway... back to the tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tune the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: No measure specified. Setting measure=RootMeanSquaredError(). \n",
      "└ @ MLJTuning /Users/michaelherman/.julia/packages/MLJTuning/Al9yX/src/tuned_models.jl:308\n",
      "┌ Info: Training Machine{DeterministicTunedModel{Grid,…},…}.\n",
      "└ @ MLJBase /Users/michaelherman/.julia/packages/MLJBase/MuLnJ/src/machines.jl:464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Attempting to evaluate 100 models.\n",
      "└ @ MLJTuning /Users/michaelherman/.julia/packages/MLJTuning/Al9yX/src/tuned_models.jl:680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   0%[>                        ]  ETA: N/A\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   1%[>                        ]  ETA: 0:01:36\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   2%[>                        ]  ETA: 0:01:15\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   3%[>                        ]  ETA: 0:00:49\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   4%[=>                       ]  ETA: 0:00:37\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   5%[=>                       ]  ETA: 0:00:29\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   6%[=>                       ]  ETA: 0:00:24\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   7%[=>                       ]  ETA: 0:00:20\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   8%[==>                      ]  ETA: 0:00:18\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:   9%[==>                      ]  ETA: 0:00:16\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  10%[==>                      ]  ETA: 0:00:14\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  11%[==>                      ]  ETA: 0:00:14\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  12%[===>                     ]  ETA: 0:00:13\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  13%[===>                     ]  ETA: 0:00:13\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  14%[===>                     ]  ETA: 0:00:12\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  15%[===>                     ]  ETA: 0:00:11\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  16%[====>                    ]  ETA: 0:00:10\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  17%[====>                    ]  ETA: 0:00:10\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  18%[====>                    ]  ETA: 0:00:09\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  19%[====>                    ]  ETA: 0:00:08\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  20%[=====>                   ]  ETA: 0:00:08\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  21%[=====>                   ]  ETA: 0:00:07\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  22%[=====>                   ]  ETA: 0:00:07\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  23%[=====>                   ]  ETA: 0:00:07\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  24%[======>                  ]  ETA: 0:00:06\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  25%[======>                  ]  ETA: 0:00:06\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  26%[======>                  ]  ETA: 0:00:06\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  27%[======>                  ]  ETA: 0:00:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  28%[=======>                 ]  ETA: 0:00:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  29%[=======>                 ]  ETA: 0:00:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  30%[=======>                 ]  ETA: 0:00:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  31%[=======>                 ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  32%[========>                ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  33%[========>                ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  34%[========>                ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  35%[========>                ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  36%[=========>               ]  ETA: 0:00:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  37%[=========>               ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  38%[=========>               ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  39%[=========>               ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  40%[==========>              ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  41%[==========>              ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  42%[==========>              ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  43%[==========>              ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  44%[===========>             ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  45%[===========>             ]  ETA: 0:00:03\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  46%[===========>             ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  47%[===========>             ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  48%[============>            ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  49%[============>            ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  50%[============>            ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  51%[============>            ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  52%[=============>           ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  53%[=============>           ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  54%[=============>           ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  55%[=============>           ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  56%[==============>          ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  57%[==============>          ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  58%[==============>          ]  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  59%[==============>          ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  60%[===============>         ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  61%[===============>         ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  62%[===============>         ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  63%[===============>         ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  64%[================>        ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  65%[================>        ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  66%[================>        ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  67%[================>        ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  68%[=================>       ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  69%[=================>       ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  70%[=================>       ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  71%[=================>       ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  72%[==================>      ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  73%[==================>      ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  74%[==================>      ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  76%[===================>     ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  77%[===================>     ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  78%[===================>     ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  79%[===================>     ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  80%[====================>    ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  81%[====================>    ]  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  82%[====================>    ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  83%[====================>    ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  84%[=====================>   ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  85%[=====================>   ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  86%[=====================>   ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  87%[=====================>   ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  88%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  89%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  90%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  91%[======================>  ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  92%[=======================> ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  93%[=======================> ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  94%[=======================> ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  95%[=======================> ]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  96%[========================>]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  97%[========================>]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  98%[========================>]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels:  99%[========================>]  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[33mEvaluating over 100 metamodels: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "tm = TunedModel(model=ensemble_model,\n",
    "                tuning=Grid(resolution=10),\n",
    "                resampling=Holdout(fraction_train=0.8, rng=StableRNG(42)),\n",
    "                range=[B_range, K_range])\n",
    "\n",
    "tuned_ensemble = machine(tm, X, y)\n",
    "fit!(tuned_ensemble, rows=train);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can report the `best_` results. This is the grid values that gave the best score (lowest rms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_ensemble.model.K = 3\n",
      "best_ensemble.bagging_fraction = 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "best_ensemble = fitted_params(tuned_ensemble).best_model\n",
    "@show best_ensemble.model.K\n",
    "@show best_ensemble.bagging_fraction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       " 0.08095744884424856\n",
       " 0.05594262067828829\n",
       " 0.08987186363535576\n",
       " 0.047610083874345954\n",
       " 0.051221210220817534\n",
       " 0.08323011101686068\n",
       " 0.06957083713529455\n",
       " 0.05120397757214792\n",
       " 0.10403438991921876\n",
       " 0.060740138881097805\n",
       " ⋮\n",
       " 0.04993209400046543\n",
       " 0.09350946957795214\n",
       " 0.046116939590707035\n",
       " 0.06861638837200117\n",
       " 0.08052801461903265\n",
       " 0.0564010499185249\n",
       " 0.0564010499185249\n",
       " 0.07766627832011186\n",
       " 0.07766627832011186"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = report(tuned_ensemble);\n",
    "r.plotting.measurements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we can use the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms(ŷ, y[test]) = 0.05210454189997038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05210454189997038"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ŷ = predict(tuned_ensemble, rows=test)\n",
    "@show rms(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
